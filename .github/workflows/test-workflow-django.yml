name: Run Django Unit Test with Coverage, Check the Migration, Run Sonar and Linting Quality Checks

on:
  workflow_dispatch:
  push:

jobs:
  test:
    name: Django Tests With Postgres and Coverage
    strategy:
      matrix:
        python_version: [ "3.11.2" ]
        poetry_version: [ '1.8.4' ]
    runs-on: ubuntu-latest
    container: python:${{ matrix.python_version }}-alpine

    services:
      postgres:
        image: ${{ (true) && 'postgres:17-alpine' || '' }}  #INPUT
        env:
          POSTGRES_DB: ${{ vars.POSTGRES_DB }}
          POSTGRES_USER: ${{ vars.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install needed apk packages
        run: apk update && apk add bash && apk add zstd && apk add tar

      - name: Load cache
        id: cache
        uses: actions/cache@v4
        with:
          path: |
            django-test/.testmondata
            django-test/.coverage
            coverage.xml
            django-test/.venv
            /github/home/.local
          key: cache-poetry-${{ matrix.poetry_version }}-python-${{ matrix.python_version }}-${{ hashFiles('**/poetry.lock') }}

#      - name: Always save cache
#        id: cache-primes-save
#        if: always() && steps.cache.outputs.cache-hit != 'true'
#        uses: actions/cache/save@v4
#        with:
#          key: cache-poetry-${{ matrix.poetry_version }}-python-${{ matrix.python_version }}-${{ hashFiles('**/poetry.lock') }}
#          path: |
#            django-test/.venv
#            django-test/.testmondata
#            /github/home/.local

      - name: Add cache to path
        if: steps.cache.outputs.cache-hit == 'true'
        run: echo "/github/home/.local/bin" >> $GITHUB_PATH

      - name: Install Poetry V${{ matrix.poetry_version }}
        if: steps.cache.outputs.cache-hit != 'true'
        uses: snok/install-poetry@v1
        with:
          version: ${{ matrix.poetry_version }}
          virtualenvs-create: true
          virtualenvs-in-project: true
          installer-parallel: true

      - name: Check pyproject.toml
        working-directory: django-test #INPUTs
        run: |
          INSTALL_MSG=$(poetry install --dry-run 2>&1 | tail -1)
          if [[ "$INSTALL_MSG" != '' ]]; then
            echo "<h2>:no_entry_sign: Poetry install dry-run failed </h2>
                    <h3>You should probably run 'poetry lock' </h3>
                    <br/> $INSTALL_MSG" >> $GITHUB_STEP_SUMMARY
            exit 3
          fi

      - name: Poetry; configure and install packages
        working-directory: django-test #INPUT
        if: steps.cache.outputs.cache-hit != 'true'
        run: |
          poetry config repositories.repowered ${{ secrets.PRIVATE_PYPI_URL}}
          poetry config http-basic.repowered ${{ secrets.PRIVATE_PYPI_USER }} ${{ secrets.PRIVATE_PYPI_PASSWORD}}
          poetry config --list
          poetry install --no-interaction --no-root --no-ansi

      #INPUT FOR PROCS
      - name: Run tests with coverage (${{vars.PARALLEL_TEST_PROCS}} test parallel procs, MD report on failures, testmon(-noselect) on branch, 5 slowest tests)
        working-directory: django-test #INPUT
        run: |
          if [ ${{ env.IS_STANDARD_BRANCH }} == 'true' ]; then
            TEST_MON_FLAG=--testmon-noselect;
          else
            TEST_MON_FLAG=--testmon;
          fi
            echo "Running pytest with flag $TEST_MON_FLAG and ${{vars.PARALLEL_TEST_PROCS}} parallel processes"
          poetry run pytest -v \
            "$TEST_MON_FLAG" --durations=5 -n ${{vars.PARALLEL_TEST_PROCS}} \
            --cov-report=term --cov-report=xml --cov=. --cov-append \
            --md-report --md-report-flavor gfm --md-report-exclude-outcomes passed skipped xpassed --md-report-output test_report.md
        env:
          CI: true
          IS_STANDARD_BRANCH: ${{ endsWith( GITHUB.REF, 'main') || endsWith( GITHUB.REF, 'dev') 
            || contains( GITHUB.REF, 'release/') || contains( GITHUB.REF, 'hotfix/') }}
          SQL_DATABASE: ${{ vars.POSTGRES_DB }}
          SQL_USER: ${{ vars.POSTGRES_USER }}
          SQL_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          SQL_HOST: ${{ vars.POSTGRES_HOST }}
          SQL_PORT: 5432

      - name: Show test failures in the job summary
        working-directory: django-test #INPUTd
        if: failure()
        run: |
          if [ -f test_report.md ]; then
            echo "<summary>:x: Tests Failed</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            cat test_report.md >> $GITHUB_STEP_SUMMARY
          else
            echo "Tests failed but report file 'test_report.md' was not generated"
          fi

#      - name: Archive test coverage report
#        uses: actions/upload-artifact@v4
#        with:
#          name: coverage.xml
#          path: django-test/
#          if-no-files-found: 'error'

